{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Getting 12963 valid examples from training set.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "class Webis17:\n",
    "    truth_file = None\n",
    "    problem_file = None\n",
    "    corpus = [] # (title, paragraphs, label)\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.truth_file = path + 'truth.jsonl'\n",
    "        self.problem_file = path + 'instances.jsonl'\n",
    "\n",
    "    def get_truths(self, size=100):\n",
    "        df = pd.read_json(self.truth_file, lines=True)\n",
    "        df = df.loc[:size, :]\n",
    "        return df['id'], df['truthMean'].values\n",
    "\n",
    "    def get_texts(self, size=100):\n",
    "        df = pd.read_json(self.problem_file, lines=True)\n",
    "        df = df.loc[:size, :]\n",
    "        return df['id'], df['targetTitle'], df['targetParagraphs']\n",
    "\n",
    "    def build_corpus(self, size=100):\n",
    "        (truth_id, label) = self.get_truths(size)\n",
    "        ground_truth = {truth_id[i] : label[i] for i in range(len(label))}\n",
    "        (tweet_id, titles, texts) = self.get_texts(size)\n",
    "        for i, tid in enumerate(tweet_id):\n",
    "            try:\n",
    "                if abs(ground_truth[tid] - 0.5) > 0.2: # getting only high confidence examples\n",
    "                    self.corpus.append( (titles[i], ' '.join(txt for txt in texts[i]), ground_truth[tid]) ) # tid is discarded from now on\n",
    "            except KeyError:\n",
    "                print(f'Tweet {tid} is not in ground truth!')\n",
    "                pass\n",
    "        print(f'Getting {len(self.corpus)} valid examples from training set.')\n",
    "web17 = Webis17('./data/clickbait17/')\n",
    "web17.build_corpus(size=19538)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "sentences = []\n",
    "truths = []\n",
    "for tweet in web17.corpus:\n",
    "    title, paragraph, label = tweet\n",
    "    seconds = []\n",
    "    # for each sent in paragraph, pair it with the text\n",
    "    for sent in nltk.sent_tokenize(paragraph):\n",
    "        seconds.append( sent )\n",
    "    sentences.append((title, seconds))\n",
    "    truths.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attentions(outputs, layer=0, attention_head=0, avg=False):\n",
    "    '''\n",
    "    get the particular output for a particular layer and attention head\n",
    "    layer -> 0 to 11\n",
    "    attention_head -> 0 to 11\n",
    "    '''\n",
    "    if avg:\n",
    "        #avg over all attention heads in a layer\n",
    "        return outputs[layer].squeeze(0).mean(dim=0)  \n",
    "    #return values for a particular attention head inside a specific layer\n",
    "    return outputs[layer].squeeze(0)[attention_head]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertModel\n",
    "from transformers import AutoTokenizer\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True,)\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "bert_model.eval()\n",
    "COS = torch.nn.CosineSimilarity()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tweet):\n",
    "    title, sents = tweet\n",
    "    titles = [title] * len(sents)\n",
    "    input1 = tokenizer(titles, padding='max_length', max_length=200, return_tensors=\"pt\", truncation=True) #'longest_first', \n",
    "    input2 = tokenizer(sents,  padding='max_length', max_length=200, return_tensors=\"pt\", truncation=True) #'longest_first', \n",
    "    with torch.no_grad():\n",
    "        outputs1 = bert_model(**input1)\n",
    "        outputs2 = bert_model(**input2)\n",
    "        attention1 = get_attentions(outputs1).detach()\n",
    "        attention2 = get_attentions(outputs2).detach()\n",
    "        score = torch.mean(COS(attention1, attention2)).item() \n",
    "        print(f'Getting score {score}')\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Getting score 0.7008105516433716\n",
      "Getting score 0.7388438582420349\n",
      "Getting score 0.6172273755073547\n",
      "Getting score 0.7433063387870789\n",
      "Getting score 0.6820316314697266\n",
      "Getting score 0.7619144916534424\n",
      "Getting score 0.6675407886505127\n",
      "Getting score 0.7138804793357849\n",
      "Getting score 0.7003026604652405\n",
      "Getting score 0.6875993609428406\n",
      "Getting score 0.6018338203430176\n",
      "Getting score 0.7119781374931335\n",
      "Getting score 0.6856278777122498\n",
      "Getting score 0.6959887146949768\n",
      "Getting score 0.7289766073226929\n",
      "Getting score 0.692633867263794\n",
      "Getting score 0.708162248134613\n",
      "Getting score 0.5801752209663391\n",
      "Getting score 0.6705156564712524\n",
      "Getting score 0.6926488280296326\n",
      "Getting score 0.7155680656433105\n",
      "Getting score 0.5657832026481628\n",
      "Getting score 0.7177940607070923\n",
      "Getting score 0.689022421836853\n",
      "Getting score 0.688876748085022\n",
      "Getting score 0.6826866269111633\n",
      "Getting score 0.6525300741195679\n",
      "Getting score 0.7206486463546753\n",
      "Getting score 0.6963037848472595\n",
      "Getting score 0.6602123379707336\n",
      "Getting score 0.7904325723648071\n",
      "Getting score 0.7011169195175171\n",
      "Getting score 0.662585973739624\n",
      "Getting score 0.6779373288154602\n",
      "Getting score 0.6263464093208313\n",
      "Getting score 0.6946758031845093\n",
      "Getting score 0.6753572225570679\n",
      "Getting score 0.6487230062484741\n",
      "Getting score 0.6247993111610413\n",
      "Getting score 0.6619281768798828\n",
      "Getting score 0.6702120900154114\n",
      "Getting score 0.6640821099281311\n",
      "Getting score 0.6393865942955017\n",
      "Getting score 0.7397641539573669\n",
      "Getting score 0.7571209669113159\n",
      "Getting score 0.7278798818588257\n",
      "Getting score 0.7112093567848206\n",
      "Getting score 0.6899928450584412\n",
      "Getting score 0.713154673576355\n",
      "Getting score 0.6468007564544678\n",
      "Getting score 0.6257182955741882\n",
      "Getting score 0.7253482341766357\n",
      "Getting score 0.6135597825050354\n",
      "Getting score 0.6508603692054749\n",
      "Getting score 0.7078457474708557\n",
      "Getting score 0.7058883905410767\n",
      "Getting score 0.7221654653549194\n",
      "Getting score 0.674186110496521\n",
      "Getting score 0.7095717787742615\n",
      "Getting score 0.6358685493469238\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-6ff906509670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtruths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-6ff906509670>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtruths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-449b0d1d6313>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(tweet)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#print(attention1.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#print(attention2.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Getting score {score}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/distance.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "test_size = 500\n",
    "\n",
    "predictions = [predict(sentences[i]) for i in range(test_size)]\n",
    "labels = truths[:test_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The overall score (pearsonr) on the test set is 0.5278372703794054.\n"
     ]
    }
   ],
   "source": [
    "cos_vec = torch.nn.CosineSimilarity(dim=0)\n",
    "from scipy.stats import pearsonr\n",
    "print(f'The overall score (pearsonr) on the test set is {pearsonr(np.array(predictions), np.array(labels))[1]}.')"
   ]
  }
 ]
}
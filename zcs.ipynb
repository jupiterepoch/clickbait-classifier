{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Getting 12963 valid examples from training set.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "class Webis17:\n",
    "    truth_file = None\n",
    "    problem_file = None\n",
    "    corpus = [] # (title, paragraphs, label)\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.truth_file = path + 'truth.jsonl'\n",
    "        self.problem_file = path + 'instances.jsonl'\n",
    "\n",
    "    def get_truths(self, size=100):\n",
    "        df = pd.read_json(self.truth_file, lines=True)\n",
    "        df = df.loc[:size, :]\n",
    "        return df['id'], df['truthMean'].values\n",
    "\n",
    "    def get_texts(self, size=100):\n",
    "        df = pd.read_json(self.problem_file, lines=True)\n",
    "        df = df.loc[:size, :]\n",
    "        return df['id'], df['targetTitle'], df['targetParagraphs']\n",
    "\n",
    "    def build_corpus(self, size=100):\n",
    "        (truth_id, label) = self.get_truths(size)\n",
    "        ground_truth = {truth_id[i] : label[i] for i in range(len(label))}\n",
    "        (tweet_id, titles, texts) = self.get_texts(size)\n",
    "        for i, tid in enumerate(tweet_id):\n",
    "            try:\n",
    "                if abs(ground_truth[tid] - 0.5) > 0.2: # getting only high confidence examples\n",
    "                    self.corpus.append( (titles[i], ' '.join(txt for txt in texts[i]), ground_truth[tid]) ) # tid is discarded from now on\n",
    "            except KeyError:\n",
    "                print(f'Tweet {tid} is not in ground truth!')\n",
    "                pass\n",
    "        print(f'Getting {len(self.corpus)} valid examples from training set.')\n",
    "web17 = Webis17('./data/clickbait17/')\n",
    "web17.build_corpus(size=19538)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "sentences = []\n",
    "truths = []\n",
    "for tweet in web17.corpus:\n",
    "    title, paragraph, label = tweet\n",
    "    seconds = []\n",
    "    # for each sent in paragraph, pair it with the text\n",
    "    for sent in nltk.sent_tokenize(paragraph):\n",
    "        seconds.append( sent )\n",
    "    sentences.append((title, seconds))\n",
    "    truths.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attentions(outputs, layer=0, attention_head=0, avg=False):\n",
    "    '''\n",
    "    get the particular output for a particular layer and attention head\n",
    "    layer -> 0 to 11\n",
    "    attention_head -> 0 to 11\n",
    "    '''\n",
    "    if avg:\n",
    "        #avg over all attention heads in a layer\n",
    "        return outputs[layer].squeeze(0).mean(dim=0)  \n",
    "    #return values for a particular attention head inside a specific layer\n",
    "    return outputs[layer].squeeze(0)[attention_head]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertModel\n",
    "from transformers import AutoTokenizer\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True,)\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "bert_model.eval()\n",
    "COS = torch.nn.CosineSimilarity()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tweet):\n",
    "    title, sents = tweet\n",
    "    titles = [title] * len(sents)\n",
    "    input1 = tokenizer(titles, padding='max_length', max_length=200, return_tensors=\"pt\", truncation=True) #'longest_first', \n",
    "    input2 = tokenizer(sents,  padding='max_length', max_length=200, return_tensors=\"pt\", truncation=True) #'longest_first', \n",
    "    with torch.no_grad():\n",
    "        outputs1 = bert_model(**input1)\n",
    "        outputs2 = bert_model(**input2)\n",
    "        attention1 = get_attentions(outputs1).detach()\n",
    "        attention2 = get_attentions(outputs2).detach()\n",
    "        score = torch.mean(COS(attention1, attention2)).item() \n",
    "        print(f'Getting score {score}')\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Getting score 0.7008105516433716\n",
      "Getting score 0.7388438582420349\n",
      "Getting score 0.6172273755073547\n",
      "Getting score 0.7433063387870789\n",
      "Getting score 0.6820316314697266\n",
      "Getting score 0.7619144916534424\n",
      "Getting score 0.6675407886505127\n",
      "Getting score 0.7138804793357849\n",
      "Getting score 0.7003026604652405\n",
      "Getting score 0.6875993609428406\n"
     ]
    }
   ],
   "source": [
    "test_size = 1000\n",
    "\n",
    "predictions = [predict(sentences[i]) for i in range(test_size)]\n",
    "labels = truths[:test_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The overall score on the test set is 0.6527574062347412.\n"
     ]
    }
   ],
   "source": [
    "cos_vec = torch.nn.CosineSimilarity(dim=0)\n",
    "print(f'The overall score on the test set is {cos_vec(torch.tensor(predictions), torch.tensor(labels)).item()}.')"
   ]
  }
 ]
}